{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/matterhorn-studio/MHSapi.git"
      ],
      "metadata": {
        "id": "m1FomtyDusn2",
        "outputId": "69b72575-d6ca-42d2-f4af-84b1243ba289",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/matterhorn-studio/MHSapi.git\n",
            "  Cloning https://github.com/matterhorn-studio/MHSapi.git to /tmp/pip-req-build-vtqs5wmq\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/matterhorn-studio/MHSapi.git /tmp/pip-req-build-vtqs5wmq\n",
            "  Resolved https://github.com/matterhorn-studio/MHSapi.git to commit e6beb1788ddab337665968fb08389c6ac21627af\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting aiopenapi3 (from MHSapi==0.0.2)\n",
            "  Downloading aiopenapi3-0.5.0-py3-none-any.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.3/83.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from MHSapi==0.0.2) (1.5.3)\n",
            "Collecting pydantic==2.4.2 (from MHSapi==0.0.2)\n",
            "  Downloading pydantic-2.4.2-py3-none-any.whl (395 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.8/395.8 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting annotated-types>=0.4.0 (from pydantic==2.4.2->MHSapi==0.0.2)\n",
            "  Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
            "Collecting pydantic-core==2.10.1 (from pydantic==2.4.2->MHSapi==0.0.2)\n",
            "  Downloading pydantic_core-2.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions>=4.6.1 (from pydantic==2.4.2->MHSapi==0.0.2)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: PyYaml in /usr/local/lib/python3.10/dist-packages (from aiopenapi3->MHSapi==0.0.2) (6.0.1)\n",
            "Collecting email-validator (from aiopenapi3->MHSapi==0.0.2)\n",
            "  Downloading email_validator-2.1.0.post1-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: yarl in /usr/local/lib/python3.10/dist-packages (from aiopenapi3->MHSapi==0.0.2) (1.9.4)\n",
            "Collecting httpx (from aiopenapi3->MHSapi==0.0.2)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from aiopenapi3->MHSapi==0.0.2) (10.1.0)\n",
            "Collecting jmespath (from aiopenapi3->MHSapi==0.0.2)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->MHSapi==0.0.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->MHSapi==0.0.2) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas->MHSapi==0.0.2) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->MHSapi==0.0.2) (1.16.0)\n",
            "Collecting dnspython>=2.0.0 (from email-validator->aiopenapi3->MHSapi==0.0.2)\n",
            "  Downloading dnspython-2.5.0-py3-none-any.whl (305 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.4/305.4 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email-validator->aiopenapi3->MHSapi==0.0.2) (3.6)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->aiopenapi3->MHSapi==0.0.2) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->aiopenapi3->MHSapi==0.0.2) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx->aiopenapi3->MHSapi==0.0.2)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->aiopenapi3->MHSapi==0.0.2) (1.3.0)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->aiopenapi3->MHSapi==0.0.2)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: multidict>=4.0 in /usr/local/lib/python3.10/dist-packages (from yarl->aiopenapi3->MHSapi==0.0.2) (6.0.4)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->aiopenapi3->MHSapi==0.0.2) (1.2.0)\n",
            "Building wheels for collected packages: MHSapi\n",
            "  Building wheel for MHSapi (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for MHSapi: filename=mhsapi-0.0.2-py3-none-any.whl size=3168 sha256=8542ebce7236f3caa2397c15b656b86d8320daf07f3c0740f3d3dffd3d5b4aeb\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-dwujnzo7/wheels/64/16/96/87d5f2f83db0e65d4228308d03ec637537803fd5fbb0085c45\n",
            "Successfully built MHSapi\n",
            "Installing collected packages: typing-extensions, jmespath, h11, dnspython, annotated-types, pydantic-core, httpcore, email-validator, pydantic, httpx, aiopenapi3, MHSapi\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.14\n",
            "    Uninstalling pydantic-1.10.14:\n",
            "      Successfully uninstalled pydantic-1.10.14\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MHSapi-0.0.2 aiopenapi3-0.5.0 annotated-types-0.6.0 dnspython-2.5.0 email-validator-2.1.0.post1 h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 jmespath-1.0.1 pydantic-2.4.2 pydantic-core-2.10.1 typing-extensions-4.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pydantic\n",
        "pydantic.__version__"
      ],
      "metadata": {
        "id": "kVvUaB8Su3v4",
        "outputId": "cd1cac5e-cb53-4b42-9496-b4b6e8d67d8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.4.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "tags": [
          "parameters"
        ],
        "id": "idz8AuW_ZRjc"
      },
      "outputs": [],
      "source": [
        "# Parameters, to be overwritten by papermill when run as nextflow pipeline\n",
        "project_id = \"1267\"\n",
        "opt_run_id = \"481\"\n",
        "token = \"1710e78f131e1f6d5cc903ff636821ce8988beb96a5838be4804e1d88caea969\"\n",
        "base_url = \"https://matterhorn.studio/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "7gg-ZRooZRje",
        "outputId": "d157faaf-2bff-4011-a2dd-4c548e0d4460",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content', '/env/python', '/usr/lib/python310.zip', '/usr/lib/python3.10', '/usr/lib/python3.10/lib-dynload', '', '/usr/local/lib/python3.10/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.10/dist-packages/IPython/extensions', '/root/.ipython']\n"
          ]
        }
      ],
      "source": [
        "# Packages\n",
        "import sys\n",
        "print(sys.path)\n",
        "import json\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "9x1qmwxmZRjf",
        "outputId": "efcb6e9b-1e1c-4b78-dea0-98586d3a0316",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BASE URL: https://matterhorn.studio/\n",
            "0.0.2\n",
            "/usr/local/lib/python3.10/dist-packages/MHSapi/__init__.py\n",
            "['MHSapi', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__']\n",
            "['__class__', '__delattr__', '__dir__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'experiment_data', 'experiment_update_data', 'experiments_create', 'experiments_list', 'get_base_url', 'open_experiment', 'opt_run_list', 'parameters_create', 'parameters_list']\n",
            "{}\n",
            "[Experiment(id=1267, url='https://matterhorn.studio/experiments/1267/', name_text='Photonite-2024', data_table_json=''), Experiment(id=1196, url='https://matterhorn.studio/experiments/1196/', name_text='Photonite-2024', data_table_json=''), Experiment(id=1195, url='https://matterhorn.studio/experiments/1195/', name_text='Photonite-2024', data_table_json=''), Experiment(id=1193, url='https://matterhorn.studio/experiments/1193/', name_text='Photonite-2024', data_table_json=''), Experiment(id=1187, url='https://matterhorn.studio/experiments/1187/', name_text='Photonite-2024', data_table_json=''), Experiment(id=1185, url='https://matterhorn.studio/experiments/1185/', name_text='Photonite-2024', data_table_json=''), Experiment(id=1143, url='https://matterhorn.studio/experiments/1143/', name_text='Photonite-2024', data_table_json=''), Experiment(id=1129, url='https://matterhorn.studio/experiments/1129/', name_text='Photonite-2024', data_table_json=''), Experiment(id=1122, url='https://matterhorn.studio/experiments/1122/', name_text='Photonite-2024', data_table_json=''), Experiment(id=1121, url='https://matterhorn.studio/experiments/1121/', name_text='Photonite-2024', data_table_json=''), Experiment(id=1120, url='https://matterhorn.studio/experiments/1120/', name_text='Photonite-2024', data_table_json=''), Experiment(id=1080, url='https://matterhorn.studio/experiments/1080/', name_text='Photonite-2023', data_table_json=''), Experiment(id=1070, url='https://matterhorn.studio/experiments/1070/', name_text='Photonite-2023', data_table_json=''), Experiment(id=1023, url='https://matterhorn.studio/experiments/1023/', name_text='Photonite-2023', data_table_json=''), Experiment(id=1004, url='https://matterhorn.studio/experiments/1004/', name_text='Photonite-2023', data_table_json=''), Experiment(id=1002, url='https://matterhorn.studio/experiments/1002/', name_text='Photonite-2023', data_table_json=''), Experiment(id=987, url='https://matterhorn.studio/experiments/987/', name_text='Photonite-2023', data_table_json=''), Experiment(id=966, url='https://matterhorn.studio/experiments/966/', name_text='Photonite-2023', data_table_json=''), Experiment(id=965, url='https://matterhorn.studio/experiments/965/', name_text='Photonite-2023', data_table_json=''), Experiment(id=964, url='https://matterhorn.studio/experiments/964/', name_text='Photonite-2023', data_table_json=''), Experiment(id=963, url='https://matterhorn.studio/experiments/963/', name_text='Photonite-2023', data_table_json=''), Experiment(id=958, url='https://matterhorn.studio/experiments/958/', name_text='SynGas', data_table_json=''), Experiment(id=956, url='https://matterhorn.studio/experiments/956/', name_text='Photonite-2023', data_table_json=''), Experiment(id=941, url='https://matterhorn.studio/experiments/941/', name_text='FRCoating', data_table_json=''), Experiment(id=936, url='https://matterhorn.studio/experiments/936/', name_text='Photonite-2023', data_table_json=''), Experiment(id=930, url='https://matterhorn.studio/experiments/930/', name_text='Photonite-2023', data_table_json=''), Experiment(id=927, url='https://matterhorn.studio/experiments/927/', name_text='Photonite-2023', data_table_json=''), Experiment(id=845, url='https://matterhorn.studio/experiments/845/', name_text='Photonite-2023', data_table_json=''), Experiment(id=835, url='https://matterhorn.studio/experiments/835/', name_text='SuperL', data_table_json=''), Experiment(id=833, url='https://matterhorn.studio/experiments/833/', name_text='Photonite-2023', data_table_json=''), Experiment(id=831, url='https://matterhorn.studio/experiments/831/', name_text='Photonite-2023', data_table_json=''), Experiment(id=793, url='https://matterhorn.studio/experiments/793/', name_text='Photonite-2023', data_table_json=''), Experiment(id=780, url='https://matterhorn.studio/experiments/780/', name_text='Syngas', data_table_json=''), Experiment(id=767, url='https://matterhorn.studio/experiments/767/', name_text='Photonite-2023', data_table_json=''), Experiment(id=765, url='https://matterhorn.studio/experiments/765/', name_text='Photonite-2023', data_table_json=''), Experiment(id=764, url='https://matterhorn.studio/experiments/764/', name_text='Photonite-2023', data_table_json=''), Experiment(id=758, url='https://matterhorn.studio/experiments/758/', name_text='Photonite-2023', data_table_json=''), Experiment(id=757, url='https://matterhorn.studio/experiments/757/', name_text='Photonite-2023', data_table_json=''), Experiment(id=755, url='https://matterhorn.studio/experiments/755/', name_text='Photonite-2023', data_table_json=''), Experiment(id=753, url='https://matterhorn.studio/experiments/753/', name_text='Photonite-2023', data_table_json=''), Experiment(id=752, url='https://matterhorn.studio/experiments/752/', name_text='Photonite-2023', data_table_json=''), Experiment(id=751, url='https://matterhorn.studio/experiments/751/', name_text='YeastMediaOpt', data_table_json=''), Experiment(id=750, url='https://matterhorn.studio/experiments/750/', name_text='Photonite-2023', data_table_json=''), Experiment(id=737, url='https://matterhorn.studio/experiments/737/', name_text='Photonite-2023', data_table_json=''), Experiment(id=605, url='https://matterhorn.studio/experiments/605/', name_text='Photonite-2023', data_table_json=''), Experiment(id=594, url='https://matterhorn.studio/experiments/594/', name_text='Photonite-2023', data_table_json=''), Experiment(id=588, url='https://matterhorn.studio/experiments/588/', name_text='Photonite-2023', data_table_json=''), Experiment(id=579, url='https://matterhorn.studio/experiments/579/', name_text='Photonite-2023', data_table_json=''), Experiment(id=571, url='https://matterhorn.studio/experiments/571/', name_text='Vlad', data_table_json=''), Experiment(id=570, url='https://matterhorn.studio/experiments/570/', name_text='Photonite-2023', data_table_json=''), Experiment(id=445, url='https://matterhorn.studio/experiments/445/', name_text='Photonite-2023', data_table_json=''), Experiment(id=441, url='https://matterhorn.studio/experiments/441/', name_text='Photonite-2023', data_table_json=''), Experiment(id=346, url='https://matterhorn.studio/experiments/346/', name_text='Photonite-2023', data_table_json=''), Experiment(id=285, url='https://matterhorn.studio/experiments/285/', name_text='Photonite-2023', data_table_json=''), Experiment(id=284, url='https://matterhorn.studio/experiments/284/', name_text='Photonite-2023', data_table_json=''), Experiment(id=197, url='https://matterhorn.studio/experiments/197/', name_text='Photonite-2023', data_table_json=''), Experiment(id=188, url='https://matterhorn.studio/experiments/188/', name_text='Photonite-2023', data_table_json=''), Experiment(id=187, url='https://matterhorn.studio/experiments/187/', name_text='Photonite-2023', data_table_json=''), Experiment(id=157, url='https://matterhorn.studio/experiments/157/', name_text='Photonite-2023', data_table_json=''), Experiment(id=155, url='https://matterhorn.studio/experiments/155/', name_text='Photonite-2023', data_table_json=''), Experiment(id=154, url='https://matterhorn.studio/experiments/154/', name_text='Photonite2023', data_table_json=''), Experiment(id=138, url='https://matterhorn.studio/experiments/138/', name_text='Photonite-2022', data_table_json=''), Experiment(id=137, url='https://matterhorn.studio/experiments/137/', name_text='Photonite-2022', data_table_json=''), Experiment(id=132, url='https://matterhorn.studio/experiments/132/', name_text='Photonite-2022', data_table_json=''), Experiment(id=128, url='https://matterhorn.studio/experiments/128/', name_text='Photonite-2022', data_table_json=''), Experiment(id=126, url='https://matterhorn.studio/experiments/126/', name_text='Photonite-2022', data_table_json=''), Experiment(id=125, url='https://matterhorn.studio/experiments/125/', name_text='Photonite-2022', data_table_json=''), Experiment(id=124, url='https://matterhorn.studio/experiments/124/', name_text='Photonite-2022', data_table_json=''), Experiment(id=120, url='https://matterhorn.studio/experiments/120/', name_text='Photonite-2022', data_table_json=''), Experiment(id=118, url='https://matterhorn.studio/experiments/118/', name_text='Photonite-2022', data_table_json=''), Experiment(id=113, url='https://matterhorn.studio/experiments/113/', name_text='Photonite-2022', data_table_json=''), Experiment(id=111, url='https://matterhorn.studio/experiments/111/', name_text='Photonite-2022', data_table_json=''), Experiment(id=81, url='https://matterhorn.studio/experiments/81/', name_text='Photonite-2022', data_table_json=''), Experiment(id=79, url='https://matterhorn.studio/experiments/79/', name_text='Photonite-2022', data_table_json=''), Experiment(id=62, url='https://matterhorn.studio/experiments/62/', name_text='Photonite-2022', data_table_json=''), Experiment(id=59, url='https://matterhorn.studio/experiments/59/', name_text='Photonite-2022', data_table_json=''), Experiment(id=34, url='https://matterhorn.studio/experiments/34/', name_text='Photonite-2022', data_table_json='')]\n"
          ]
        }
      ],
      "source": [
        "# 1. Initialise API client\n",
        "import MHSapi\n",
        "from MHSapi.MHSapi import MHSapiClient\n",
        "from importlib.metadata import version\n",
        "\n",
        "client = MHSapi.MHSapi.MHSapiClient(token=token, base_url=base_url)\n",
        "print(version('MHSapi'))\n",
        "print(MHSapi.__file__)\n",
        "print(dir(MHSapi))\n",
        "object_methods = [method_name for method_name in dir(client)\n",
        "                  if callable(getattr(client, method_name))]\n",
        "print(object_methods)\n",
        "\n",
        "projects = client.experiments_list()\n",
        "project = [p for p in projects if int(p.id) == int(project_id)][0]\n",
        "parameters = client.parameters_list(project)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "R2Cet9OQZRjf",
        "outputId": "cd8f772d-76c4-4a7a-aaa7-761085a2abfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"import_timestamp\":{\"0\":1706707669.0541028976,\"1\":1706707669.0541028976,\"2\":1706707669.0541028976,\"3\":1706707669.0541028976,\"4\":1706707669.0541028976,\"5\":1706707669.0541028976,\"6\":1706707669.0541028976,\"7\":1706707669.0541028976,\"8\":1706707669.0541028976},\"disabled\":{\"0\":false,\"1\":false,\"2\":false,\"3\":false,\"4\":false,\"5\":false,\"6\":false,\"7\":false,\"8\":false},\"Temperature (Celsius)\":{\"0\":10.5,\"1\":12.3,\"2\":11.7,\"3\":25.5,\"4\":28.0,\"5\":15.0,\"6\":13.5,\"7\":25.0,\"8\":26.8},\"Biomass Yield (g\\/m3)\":{\"0\":910.6302258842,\"1\":955.2308874596,\"2\":934.0850461644,\"3\":977.3216897534,\"4\":918.4279047088,\"5\":962.6146346605,\"6\":959.1759260206,\"7\":979.7014651398,\"8\":946.5538356882}}\n",
            "Data\n",
            "   import_timestamp  disabled  Temperature (Celsius)  Biomass Yield (g/m3)\n",
            "0      1.706708e+09     False                   10.5            910.630226\n",
            "1      1.706708e+09     False                   12.3            955.230887\n",
            "2      1.706708e+09     False                   11.7            934.085046\n",
            "3      1.706708e+09     False                   25.5            977.321690\n",
            "4      1.706708e+09     False                   28.0            918.427905\n",
            "5      1.706708e+09     False                   15.0            962.614635\n",
            "6      1.706708e+09     False                   13.5            959.175926\n",
            "7      1.706708e+09     False                   25.0            979.701465\n",
            "8      1.706708e+09     False                   26.8            946.553836\n"
          ]
        }
      ],
      "source": [
        "# 2. Download dataset\n",
        "dataset = client.experiment_data(project)\n",
        "print(\"Data\")\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "qVQnno-wZRjf",
        "outputId": "26b9cc2e-6283-4b32-e211-523e84f53d5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OptimisationRun(id=480, experiment=1267, opt_app=None, run_options=X9fbc5f2e_3606_41ad_b934_5b6f019354eb_(root={})), OptimisationRun(id=481, experiment=1267, opt_app=1, run_options=X9fbc5f2e_3606_41ad_b934_5b6f019354eb_(root={'batch_size': L80ee1ee16_dfb2_49f2_8d92_0c7d0014a537_(root=L80ee1ee16_dfb2_49f2_8d92_0c7d0014a537_(root=3))}))]\n",
            "id=481 experiment=1267 opt_app=1 run_options=X9fbc5f2e_3606_41ad_b934_5b6f019354eb_(root={'batch_size': L80ee1ee16_dfb2_49f2_8d92_0c7d0014a537_(root=L80ee1ee16_dfb2_49f2_8d92_0c7d0014a537_(root=3))})\n",
            "<class 'str'> {\"batch_size\":3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-2c1dc05749a9>:11: PydanticDeprecatedSince20: The `json` method is deprecated; use `model_dump_json` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.4/migration/\n",
            "  print(type(opt_run.run_options.json()), opt_run.run_options.json())\n",
            "<ipython-input-18-2c1dc05749a9>:12: PydanticDeprecatedSince20: The `json` method is deprecated; use `model_dump_json` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.4/migration/\n",
            "  run_options = json.loads(opt_run.run_options.json())\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.0"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# 3. Get OptApp options\n",
        "\n",
        "opt_runs = client.opt_run_list(project)\n",
        "print(opt_runs)\n",
        "opt_run = [p for p in opt_runs if int(p.id) == int(opt_run_id)][0]\n",
        "print(opt_run)\n",
        "#type = type(opt_run.run_options)\n",
        "#method_list = [func for func in dir(type) if callable(getattr(type, func))]\n",
        "#print(method_list)\n",
        "run_options = opt_run.run_options.model_dump()\n",
        "\n",
        "batch_size = 1\n",
        "if 'batch_size' in run_options.keys():\n",
        "    batch_size = run_options['batch_size']\n",
        "batch_size"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opt_run.run_options.model_dump()['batch_size']"
      ],
      "metadata": {
        "id": "R_wyaz-ozaYl",
        "outputId": "312179d5-6821-49d5-a09f-3b2b0bd432f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "2BgJVad6ZRjf"
      },
      "outputs": [],
      "source": [
        "|\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 4. Do BO\n",
        "import torch\n",
        "from botorch.models import SingleTaskGP\n",
        "from botorch.fit import fit_gpytorch_mll\n",
        "from botorch.utils import standardize\n",
        "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
        "\n",
        "from botorch.models.transforms.input import Normalize\n",
        "from botorch.models.transforms.outcome import Standardize\n",
        "\n",
        "inputs = [p for p in parameters if p.outcome == False and p.timestamp == False]\n",
        "outcome = [p for p in parameters if p.outcome == True][0]\n",
        "X = dataset[[i.parameter_text for i in inputs]]\n",
        "Y = dataset[[outcome.parameter_text]]\n",
        "train_X = torch.tensor(X.to_numpy(dtype=np.float64))\n",
        "train_Y = torch.tensor(Y.to_numpy(dtype=np.float64))\n",
        "#train_Y = standardize(train_Y)\n",
        "print(train_X.shape)\n",
        "print(train_X)\n",
        "print(train_Y.shape)\n",
        "print(train_Y)\n",
        "\n",
        "gp = SingleTaskGP(train_X, train_Y, input_transform=Normalize(d=train_X.shape[-1]), outcome_transform=Standardize(m=train_Y.shape[-1]))\n",
        "\n",
        "mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
        "fit_gpytorch_mll(mll)\n",
        "\n",
        "#from botorch.acquisition import UpperConfidenceBound\n",
        "#UCB = UpperConfidenceBound(gp, beta=0.1)\n",
        "\n",
        "from botorch.optim import optimize_acqf\n",
        "\n",
        "from botorch import fit_gpytorch_mll\n",
        "from botorch.acquisition.monte_carlo import (\n",
        "    qExpectedImprovement,\n",
        "    qNoisyExpectedImprovement,\n",
        ")\n",
        "from botorch.sampling.normal import SobolQMCNormalSampler\n",
        "from botorch.exceptions import BadInitialCandidatesWarning\n",
        "\n",
        "upper_bounds = torch.tensor([p.upper_bound for p in inputs])\n",
        "lower_bounds = torch.tensor([p.lower_bound for p in inputs])\n",
        "bounds = torch.stack([lower_bounds, upper_bounds])\n",
        "print(f\"batch_size={batch_size}\")\n",
        "\n",
        "SMOKE_TEST = False\n",
        "MC_SAMPLES = 256 if not SMOKE_TEST else 32\n",
        "qmc_sampler = SobolQMCNormalSampler(sample_shape=torch.Size([MC_SAMPLES]))\n",
        "\n",
        "qNEI = qNoisyExpectedImprovement(\n",
        "    model=gp,\n",
        "    X_baseline=train_X,\n",
        "    sampler=qmc_sampler,\n",
        ")\n",
        "candidates, acq_value = optimize_acqf(\n",
        "    acq_function=qNEI, bounds=bounds, q=int(batch_size), num_restarts=5, raw_samples=20,\n",
        ")\n",
        "candidates  # tensor([0.4887, 0.5063])\n",
        "print(\"Candidates (raw):\")\n",
        "print(candidates.detach())\n",
        "\n",
        "candidates = pd.DataFrame(candidates.numpy())\n",
        "candidates.columns = [input.parameter_text for input in inputs]\n",
        "candidates[outcome.parameter_text] = np.nan\n",
        "candidates[\"opt_run_id\"] = opt_run_id\n",
        "\n",
        "print(candidates)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "YrwAF0vTZRjg"
      },
      "outputs": [],
      "source": [
        "# 5. Upload candidates\n",
        "client.experiment_update_data(project, candidates)\n"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Tags",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}