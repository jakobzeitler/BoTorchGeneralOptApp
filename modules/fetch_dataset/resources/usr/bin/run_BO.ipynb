{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "tags": [
          "parameters"
        ],
        "id": "idz8AuW_ZRjc"
      },
      "outputs": [],
      "source": [
        "# Parameters, to be overwritten by papermill when run as nextflow pipeline\n",
        "project_id = \"1\"\n",
        "opt_run_id = \"1\"\n",
        "token = \"1e9549ad7e940941de51ddff92b1dc9cbe896e98b039644b9eff165e0dec9e55\"\n",
        "base_url = \"https://mhs.ngrok.app/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "7gg-ZRooZRje"
      },
      "outputs": [],
      "source": [
        "# Packages\n",
        "import sys\n",
        "print(sys.path)\n",
        "import json\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "9x1qmwxmZRjf"
      },
      "outputs": [],
      "source": [
        "# 1. Initialise API client\n",
        "import MHSapi\n",
        "from MHSapi.MHSapi import MHSapiClient\n",
        "from importlib.metadata import version\n",
        "\n",
        "client = MHSapi.MHSapi.MHSapiClient(token=token, base_url=base_url)\n",
        "print(version('MHSapi'))\n",
        "print(MHSapi.__file__)\n",
        "print(dir(MHSapi))\n",
        "object_methods = [method_name for method_name in dir(client)\n",
        "                  if callable(getattr(client, method_name))]\n",
        "print(object_methods)\n",
        "\n",
        "projects = client.experiments_list()\n",
        "project = [p for p in projects if int(p.id) == int(project_id)][0]\n",
        "parameters = client.parameters_list(project)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "R2Cet9OQZRjf"
      },
      "outputs": [],
      "source": [
        "# 2. Download dataset\n",
        "dataset = client.experiment_data(project)\n",
        "print(\"Data\")\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "qVQnno-wZRjf"
      },
      "outputs": [],
      "source": [
        "# 3. Get OptApp options\n",
        "\n",
        "opt_runs = client.opt_run_list(project)\n",
        "print(opt_runs)\n",
        "opt_run = [p for p in opt_runs if int(p.id) == int(opt_run_id)][0]\n",
        "print(opt_run)\n",
        "#type = type(opt_run.run_options)\n",
        "#method_list = [func for func in dir(type) if callable(getattr(type, func))]\n",
        "#print(method_list)\n",
        "import json\n",
        "run_options = json.loads(opt_run.run_options.json())\n",
        "\n",
        "batch_size = 1\n",
        "if 'batch_size' in run_options.keys():\n",
        "    batch_size = run_options['batch_size']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "2BgJVad6ZRjf"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 4. Do BO\n",
        "import torch\n",
        "from botorch.models import SingleTaskGP\n",
        "from botorch.fit import fit_gpytorch_mll\n",
        "from botorch.utils import standardize\n",
        "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
        "\n",
        "from botorch.models.transforms.input import Normalize\n",
        "from botorch.models.transforms.outcome import Standardize\n",
        "\n",
        "inputs = [p for p in parameters if p.outcome == False and p.timestamp == False]\n",
        "outcome = [p for p in parameters if p.outcome == True][0]\n",
        "X = dataset[[i.parameter_text for i in inputs]]\n",
        "Y = dataset[[outcome.parameter_text]]\n",
        "train_X = torch.tensor(X.to_numpy(dtype=np.float64))\n",
        "train_Y = torch.tensor(Y.to_numpy(dtype=np.float64))\n",
        "#train_Y = standardize(train_Y)\n",
        "print(train_X.shape)\n",
        "print(train_X)\n",
        "print(train_Y.shape)\n",
        "print(train_Y)\n",
        "\n",
        "gp = SingleTaskGP(train_X, train_Y, input_transform=Normalize(d=train_X.shape[-1]), outcome_transform=Standardize(m=train_Y.shape[-1]))\n",
        "\n",
        "mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
        "fit_gpytorch_mll(mll)\n",
        "\n",
        "#from botorch.acquisition import UpperConfidenceBound\n",
        "#UCB = UpperConfidenceBound(gp, beta=0.1)\n",
        "\n",
        "from botorch.optim import optimize_acqf\n",
        "\n",
        "from botorch import fit_gpytorch_mll\n",
        "from botorch.acquisition.monte_carlo import (\n",
        "    qExpectedImprovement,\n",
        "    qNoisyExpectedImprovement,\n",
        ")\n",
        "from botorch.sampling.normal import SobolQMCNormalSampler\n",
        "from botorch.exceptions import BadInitialCandidatesWarning\n",
        "\n",
        "upper_bounds = torch.tensor([p.upper_bound for p in inputs])\n",
        "lower_bounds = torch.tensor([p.lower_bound for p in inputs])\n",
        "bounds = torch.stack([lower_bounds, upper_bounds])\n",
        "print(f\"batch_size={batch_size}\")\n",
        "\n",
        "SMOKE_TEST = False\n",
        "MC_SAMPLES = 256 if not SMOKE_TEST else 32\n",
        "qmc_sampler = SobolQMCNormalSampler(sample_shape=torch.Size([MC_SAMPLES]))\n",
        "\n",
        "qNEI = qNoisyExpectedImprovement(\n",
        "    model=gp,\n",
        "    X_baseline=train_X,\n",
        "    sampler=qmc_sampler,\n",
        ")\n",
        "candidates, acq_value = optimize_acqf(\n",
        "    acq_function=qNEI, bounds=bounds, q=int(batch_size), num_restarts=5, raw_samples=20,\n",
        ")\n",
        "candidates  # tensor([0.4887, 0.5063])\n",
        "print(\"Candidates (raw):\")\n",
        "print(candidates.detach())\n",
        "\n",
        "candidates = pd.DataFrame(candidates.numpy())\n",
        "candidates.columns = [input.parameter_text for input in inputs]\n",
        "candidates[outcome.parameter_text] = np.nan\n",
        "candidates[\"opt_run_id\"] = opt_run_id\n",
        "\n",
        "print(candidates)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "YrwAF0vTZRjg"
      },
      "outputs": [],
      "source": [
        "# 5. Upload candidates\n",
        "client.experiment_update_data(project, candidates)\n"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Tags",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}